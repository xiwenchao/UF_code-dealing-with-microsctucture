# -*- coding: utf-8 -*-
"""vae.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17R_1cfK5IZ5m4sDdYFexaPmegoTM-tq4
"""

# Commented out IPython magic to ensure Python compatibility.
from __future__ import print_function
from __future__ import division
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import torchvision
from torchvision import datasets, models, transforms
# %matplotlib inline
import matplotlib.pyplot as plt
import time
import os
import copy
from torch.autograd import Variable
import os.path


torch.cuda.current_device()
import torch.nn as nn
import torch.utils.data
import seaborn as sns
sns.set_style("whitegrid")
import pickle

import random
import math
import pandas as pd
import scipy.io

from torchvision import transforms

import torch.nn as nn
import torch.utils.data
import seaborn as sns
import time

sns.set_style("whitegrid")
import torch.nn.functional as F


from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics.pairwise import pairwise_distances_argmin
import sklearn.metrics as metrics

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics.pairwise import pairwise_distances_argmin
import sklearn.metrics as metrics

torch.cuda.empty_cache()

'''
# 创建一个 FeatureFlaten 的层级
class FeatureFlaten(nn.Module):
    def __init__(self):
        super(FeatureFlaten, self).__init__()
    def forward(self, x):
        x = x.view(-1, self.num_flat_features(x))
        return x
    def num_flat_features(self, x):
        size = x.size()[1:]  # all dimensions except the batch dimension
        num_features = 1
        for s in size:
            num_features *= s
        return num_features
    def __repr__(self):
        return 'FeatureFlaten()'

'''     
      
def loss_function(recon_x, x, mu, logvar):
    """
    :param recon_x: generated image
    :param x: original image
    :param mu: latent mean of z
    :param logvar: latent log variance of z
    """
    # BCE_loss = nn.BCELoss(reduction='sum')
    MSE_loss = nn.MSELoss(reduction='sum')
    reconstruction_loss = MSE_loss(recon_x, x)/32 * 5
    
    KL_divergence = torch.mean(-0.5 * torch.sum(1+logvar-torch.exp(logvar)-mu**2))
    #KLD_ele = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)
    #KLD = torch.sum(KLD_ele).mul_(-0.5)
    # print(reconstruction_loss, KL_divergence)

    return reconstruction_loss + KL_divergence


class AutoEncoder(nn.Module):
    def __init__(self):
        super(AutoEncoder, self).__init__()
        
        
        self.fc1 = nn.Sequential(
            nn.Conv2d(3, 64, 3, stride=1, padding=1),  # b, 344, 344
            nn.ReLU(True),         
            nn.Conv2d(64, 32, 3, stride=1, padding=1), #344
            nn.ReLU(True),
            nn.Conv2d(32, 32, 3, stride=2, padding=1),  # b, 172
            nn.ReLU(True),
            nn.MaxPool2d(2, stride=2),# 86
            nn.Conv2d(32, 16, 3, stride=2, padding=1),  # b, 16, 43, 43
            nn.ReLU(True),
           # nn.MaxPool2d(2, stride=2),  # b, 10, 42, 42
            nn.Conv2d(16, 1, 3, stride=1, padding=1),  # b, 2, 43, 43
            nn.ReLU(True),          
          )
      #  self.fc2 = nn.Linear(43 * 43, 2000)
        
        self.fc2_mean = nn.Linear(43 * 43, 510)
        self.fc2_logvar = nn.Linear(43 * 43, 510)
    

        self.fc3 = nn.Sequential(
         
            nn.ConvTranspose2d(1, 16, 3, stride=1, padding=1),  # b, 
            nn.ReLU(True),           
            nn.ConvTranspose2d(16, 32, 3, stride=2, padding=1),  # b, 
            nn.ReLU(True),
            nn.Upsample(size=172, mode='nearest'),
            nn.ConvTranspose2d(32, 32, 3, stride=2, padding=1),  # b
            nn.ReLU(True),
            nn.ConvTranspose2d(32, 64, 3, stride=1, padding=1),            
            nn.ReLU(True),            
            nn.ConvTranspose2d(64, 3, 3, stride=1, padding=1),
            nn.Upsample(size=344, mode='nearest'),
            nn.Sigmoid()

          )
        self.fc4 = nn.Linear(510,43 * 43)
         
            

    def encode(self, x):
        h1 = self.fc1(x)
        # h1 = h1.view(-1, self.num_flat_features(h1))
        h1 = h1.view(h1.size(0), -1)
      # h1 = self.fc2(h1)
        return self.fc2_mean(h1), self.fc2_logvar(h1)

    def reparametrization(self, mu, logvar):
        # sigma = 0.5*exp(log(sigma^2))= 0.5*exp(log(var))
        
        std = 0.5 * torch.exp(logvar)            
        z = (torch.randn(std.size()).cuda()) * std + mu
        '''
        
        eps = torch.randn_like(logvar)        
        z = mu + torch.exp(logvar).sqrt() * eps
        # N(mu, std^2) = N(0, 1) * std + mu
        '''
       
        return z
    
    def decode(self, z):
        h3 = self.fc4(z).view(-1, 1, 43, 43)
        h3 = self.fc3(h3)
        return h3
      
    def num_flat_features(self, x):
        size = x.size()[1:]
        num_features = 1
        for s in size:
            num_features *= s
        return num_features

    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparametrization(mu, logvar)
        return self.decode(z), mu, logvar




def train(model, iterator, optimizer, clip, device, correlationCoefficientList):
    model.train()
    epoch_loss = 0

    for i, batch in enumerate(iterator):

        src = batch[0].to(device)
        
        gen_imgs, mu, logvar = model(src.float())
        loss = loss_function(gen_imgs.float(), src.float(), mu, logvar)                 
       
        optimizer.zero_grad()  # clear gradients for this training step
        loss.backward()  # backpropagation, compute gradients
        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)
        optimizer.step()  # apply gradients
        
        '''
        for p in autoencoder.parameters():
          if p.grad is not None:
            data = p.grad.data
            p.grad = Variable(data.new().resize_as_(data).zero_())
        '''

        epoch_loss += loss.item()

        if i % 20 == 0:
            print("batch lossxxx:", epoch_loss)
            
          
        if i % 60 == 0:
            img_true = src[0].cpu().numpy()
            img_true = np.transpose(img_true, (1, 2, 0))  # 把channel那一维放到最后
            plt.imshow(img_true)
            plt.show()
            
           
            img_decoded = gen_imgs[0].cpu().detach().numpy()
            img_decoded = np.transpose(img_decoded, (1, 2, 0))  # 把channel那一维放到最后
            plt.imshow(img_decoded)
            plt.show()
                   
    return epoch_loss / len(iterator), correlationCoefficientList


def evaluate(model, iterator, device, correlationCoefficientList_eva):
    model.eval()

    epoch_loss = 0

    with torch.no_grad():
      for i, batch in enumerate(iterator):
            src = batch[0].to(device)

            gen_imgs, mu, logvar = model(src.float())  # turn off teacher forcing
            loss = loss_function(gen_imgs.float(), src.float(), mu, logvar)
            epoch_loss += loss.item()
                        
            if i % 20  == 0: 
              img_true = src[0].cpu().numpy()
              img_true = np.transpose(img_true, (1, 2, 0))  # 把channel那一维放到最后
              plt.imshow(img_true)
              plt.show()
            
              img_decoded = gen_imgs[0].cpu().detach().numpy()
              img_decoded = np.transpose(img_decoded, (1, 2, 0))  # 把channel那一维放到最后
              plt.imshow(img_decoded)
              plt.show()

    return epoch_loss / len(iterator), correlationCoefficientList_eva


def epoch_time(start_time, end_time):
    elapsed_time = end_time - start_time
    elapsed_mins = int(elapsed_time / 60)
    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))
    return elapsed_mins, elapsed_secs






# normalize=transforms.Normalize(mean=[.5,.5,.5],std=[.5,.5,.5])

torch.cuda.empty_cache()
data_transforms = transforms.Compose([
        transforms.RandomResizedCrop(344),
      #  transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std= [0.229, 0.224, 0.225])
        ])


path1 = 'drive/My Drive/Colab Notebooks/UF_code/images/train/'
# 需要把图片放在"../images/train/0/"中
train_dset =  datasets.ImageFolder(path1, transform=data_transforms)
train_loader = torch.utils.data.DataLoader(train_dset,
                     batch_size=32,
                     num_workers=0,
                     shuffle=True)

path2 = 'drive/My Drive/Colab Notebooks/UF_code/images/validation/'
validation_dset =  datasets.ImageFolder(path2, transform=data_transforms)
validation_loader = torch.utils.data.DataLoader(validation_dset,
                     batch_size=32,
                     num_workers=0,
                     shuffle=True)


'''-------------------------------------------------------------------------'''
'''--------------------------- Hyper Parameters ----------------------------'''
'''-------------------------------------------------------------------------'''
EPOCH = 100
LR = 0.0002  # learning rate  0.0001
CLIP = 1
# baseline 100th measurement in Rawdata_data00025


Loading_DATA = True
SAVE_CREATED_DATA = True
WITH_MASS_LABEL = True

ANALYSIS_DATA = True
TRAIN = True
EVALUATE = False
COMPRRSSION_DATA = True
DETECTION_ANOMALY = True



device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

autoencoder = AutoEncoder().to(device)
optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR)

loss_record = []
correlationCoefficientList = []
correlationCoefficientList_eva = []


if TRAIN:


    best_valid_loss = float('inf')

    for epoch in range(EPOCH):
        # for step, (x, b_label) in enumerate(train_loader):

        start_time = time.time()
        if (epoch == 20) or (epoch == 40) or (epoch == 12):
          LR= LR/2
              
        optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR)
        
        train_loss, correlationCoefficientList = train(autoencoder, train_loader, optimizer,
                                                                             CLIP, device,
                                                                             correlationCoefficientList)
        valid_loss, correlationCoefficientList_eva = evaluate(autoencoder, validation_loader,
                                                                                    device,
                                                                                    correlationCoefficientList_eva)

        end_time = time.time()

        epoch_mins, epoch_secs = epoch_time(start_time, end_time)

        if valid_loss < best_valid_loss:
            best_valid_loss = valid_loss


        print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')
        print(f'\tTrain Loss: {train_loss:.3f}')
        print(f'\t Val. Loss: {valid_loss:.3f}')

        loss_record.append([train_loss, valid_loss])

from google.colab import drive
drive.mount('/content/drive')
