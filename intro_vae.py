# -*- coding: utf-8 -*-
"""IntroVAE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Cb6Q3ikLeFda52gmdM5-q6Ag81OZ9g_Y
"""

# Commented out IPython magic to ensure Python compatibility.
from __future__ import print_function
from __future__ import division
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import torchvision
from torchvision import datasets, models, transforms
# %matplotlib inline
import matplotlib.pyplot as plt
import time
import os
import copy
from torch.autograd import Variable
import os.path


torch.cuda.current_device()
import torch.nn as nn
import torch.utils.data
import seaborn as sns
sns.set_style("whitegrid")
import pickle

import random
import math
import pandas as pd
import scipy.io

from torchvision import transforms

import torch.nn as nn
import torch.utils.data
import seaborn as sns
import time

sns.set_style("whitegrid")
import torch.nn.functional as F


from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics.pairwise import pairwise_distances_argmin
import sklearn.metrics as metrics

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics.pairwise import pairwise_distances_argmin
import sklearn.metrics as metrics



class Flatten(nn.Module):
    def __init__(self):
        super(Flatten, self).__init__()

    def forward(self, x):
        # print('before flaten:', x.shape)
        return x.view(x.size(0), -1)

class Reshape(nn.Module):

    def __init__(self, *args):
        super(Reshape, self).__init__()
        self.shape = args

    def forward(self, x):
        return x.view(-1, *self.shape)
      
      
      
     


class Encoder(nn.Module):

    def __init__(self, imgsz, ch):
        """
        :param imgsz:
        :param ch: base channels
        """
        super(Encoder, self).__init__()

       # x = torch.randn(2, 3, imgsz, imgsz)
       
        self.net = nn.Sequential(
            nn.Conv2d(3, 64, 3, stride=1, padding=1),  # b, 344, 344
            nn.BatchNorm2d(64),
            nn.ReLU(True),
            nn.Conv2d(64, 32, 3, stride=2, padding=1), #172
            nn.BatchNorm2d(32),
            nn.ReLU(True),
            nn.MaxPool2d(2, stride=2),# 86
            nn.Conv2d(32, 16, 3, stride=2, padding=1),  # b, 16, 43, 43
            nn.BatchNorm2d(16),
            nn.ReLU(True),
           # nn.MaxPool2d(2, stride=2),  # b, 10, 42, 42
            nn.Conv2d(16, 1, 3, stride=1, padding=1),  # b, 2, 14, 14
            nn.BatchNorm2d(1),
            nn.ReLU(True),                 
            Flatten()
        )      
        

    def forward(self, x):
        """
        :param x:
        :return:
        """
        return self.net(x)



class Decoder(nn.Module):


    def __init__(self, imgsz, z_dim):
        """
        :param imgsz:
        :param z_dim:
        """
        super(Decoder, self).__init__()
     
        self.net = nn.Sequential(
            
            nn.Linear(510,43 * 43),
            Reshape(1, 43, 43),   
            nn.ReLU(inplace=True),
            
            nn.ConvTranspose2d(1, 16, 3, stride=1, padding=1),  # b,
            nn.BatchNorm2d(16),
            nn.ReLU(True),           
            nn.ConvTranspose2d(16, 32, 3, stride=2, padding=1),  # b,
            nn.BatchNorm2d(32),
            nn.ReLU(True),
            nn.Upsample(size=172, mode='nearest'),
            nn.ConvTranspose2d(32, 64, 3, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(True),
            nn.ConvTranspose2d(64, 3, 3, stride=1, padding=1),  # b
            nn.Upsample(size=344, mode='nearest'),
            nn.Sigmoid()
            )
 

    def forward(self, x):
        """
        :param x: [b, z_dim]
        :return:
        """
        # print('before forward:', x.shape)
        x =  self.net(x)
        # print('after forward:', x.shape)
        return x



class IntroVAE(nn.Module):


    def __init__(self):
        """
        :param imgsz:
        :param z_dim: h_dim is the output dim of encoder, and we use z_net net to convert it from
        h_dim to 2*z_dim and then splitting.
        """
        super(IntroVAE, self).__init__()

        imgsz = 344
        z_dim = 510        
        alpha=0.25
        beta=0.05
        gamma=1
        margin=150
        LR = 0.0001
        h_dim = 43 * 43


        # set first conv channel as 16
        self.encoder = Encoder(imgsz, 16)

        # get h_dim of encoder output
        '''
        x = torch.randn(2, 3, imgsz, imgsz)
        z_ = self.encoder(x)

        h_dim = z_.size(1)
        '''

        # convert h_dim to 2*z_dim
        self.z_net = nn.Linear(h_dim, 2 * z_dim)

        # sample
      
        # z, mu, log_sigma2 = self.reparametrization(z_)

        # create decoder by z_dim
        self.decoder = Decoder(imgsz, z_dim)
        # out = self.decoder(z)
        

        # print
        # print('IntroVAE x:', list(x.shape), 'z_:', list(z_.shape), 'z:', list(z.shape), 'out:', list(out.shape))


        self.alpha = alpha # for adversarial loss
        self.beta = beta # for reconstruction loss
        self.gamma = gamma # for variational loss
        self.margin = margin # margin in eq. 11
        self.z_dim = z_dim # z is the hidden vector while h is the output of encoder
        self.h_dim = h_dim
        self.LR = LR

        self.optim_encoder = torch.optim.Adam(self.encoder.parameters(), lr=LR)
        self.optim_decoder = torch.optim.Adam(self.decoder.parameters(), lr=LR)


    def set_alph_beta_gamma(self, alpha, beta, gamma):
        """
        this func is for pre-training, to set alpha=0 to transfer to vilina vae.
        :param alpha: for adversarial loss
        :param beta: for reconstruction loss
        :param gamma: for variational loss
        :return:
        """
        self.alpha = alpha
        self.beta = beta
        self.gamma = gamma

    def reparametrization(self, z_):
        """
        :param z_: [b, 2*z_dim]
        :return:
        """
        # [b, 2*z_dim] => [b, z_dim], [b, z_dim]
        mu, log_sigma2 = self.z_net(z_).chunk(2, dim=1)
        # sample from normal dist
        eps = torch.randn_like(log_sigma2)
        # reparametrization trick
        # mean + sigma * eps
        z = mu + torch.exp(log_sigma2).sqrt() * eps

        return z, mu, log_sigma2

    def kld(self, mu, log_sigma2):
        """
        compute the kl divergence between N(mu, sigma^2) and N(0, 1)
        :param mu: [b, z_dim]
        :param log_sigma2: [b, z_dim]
        :return:
        """
        batchsz = mu.size(0)
        # https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians
        kl = - 0.5 * (1 + log_sigma2 - torch.pow(mu, 2) - torch.exp(log_sigma2))
        kl = kl.sum() #(batchsz * self.z_dim)

        return kl

    def output_activation(self, x):
        """
        :param x:
        :return:
        """
        return torch.sigmoid(x)
               

    def forward(self, x):
        """
        The notation used here all come from Algorithm 1, page 6 of official paper.
        can refer to Figure7 in page 15 as well.
        :param x: [b, 3, 1024, 1024]
        :return:
        """
        batchsz = x.size(0)

        # 1. update encoder
        z_ = self.encoder(x)
        z, mu, log_sigma2 = self.reparametrization(z_)
        xr = self.decoder(z)
        zp = torch.randn_like(z)
        xp = self.decoder(zp)

        loss_ae = F.mse_loss(xr, x, reduction='sum').sqrt()
        reg_ae = self.kld(mu, log_sigma2)

        zr_ng_ = self.encoder(xr.detach())
        zr_ng, mur_ng, log_sigma2r_ng =  self.reparametrization(zr_ng_)
        regr_ng = self.kld(mur_ng, log_sigma2r_ng)
        # max(0, margin - l)
        regr_ng = torch.clamp(self.margin - regr_ng, min=0)
        zpp_ng_ = self.encoder(xp.detach())
        zpp_ng, mupp_ng, log_sigma2pp_ng = self.reparametrization(zpp_ng_)
        regpp_ng = self.kld(mupp_ng, log_sigma2pp_ng)
        # max(0, margin - l)
        regpp_ng = torch.clamp(self.margin - regpp_ng, min=0)


        encoder_adv = regr_ng + regpp_ng
        encoder_loss = self.gamma * reg_ae + self.alpha * encoder_adv + self.beta * loss_ae
        self.optim_encoder.zero_grad()
        encoder_loss.backward()
        self.optim_encoder.step()


        # 2. update decoder
        z_ = self.encoder(x)
        z, mu, log_sigma2 = self.reparametrization(z_)
        xr = self.decoder(z)
        zp = torch.randn_like(z)
        xp = self.decoder(zp)

        loss_ae = F.mse_loss(xr, x, reduction='sum').sqrt()

        zr_ = self.encoder(xr)
        zr, mur, log_sigma2r = self.reparametrization(zr_)
        regr = self.kld(mur, log_sigma2r)
        zpp_ = self.encoder(xp)
        zpp, mupp, log_sigma2pp = self.reparametrization(zpp_)
        regpp = self.kld(mupp, log_sigma2pp)

        # by Eq.12, the 1st term of loss
        decoder_adv = regr + regpp
        decoder_loss = self.alpha * decoder_adv + self.beta * loss_ae
        self.optim_decoder.zero_grad()
        decoder_loss.backward()
        self.optim_decoder.step()



        return encoder_loss, decoder_loss, xr


# normalize=transforms.Normalize(mean=[.5,.5,.5],std=[.5,.5,.5])

torch.cuda.empty_cache()
data_transforms = transforms.Compose([
    transforms.RandomResizedCrop(344),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor()
    
])


path1 = 'drive/My Drive/Colab Notebooks/UF_code/images/train/'
# 需要把图片放在"../images/train/0/"中
train_dset = datasets.ImageFolder(path1, transform=data_transforms)
train_loader = torch.utils.data.DataLoader(train_dset,
                                           batch_size=10,
                                           num_workers=4,
                                           shuffle=True)

path2 = 'drive/My Drive/Colab Notebooks/UF_code/images/validation/'
validation_dset = datasets.ImageFolder(path2, transform=data_transforms)
validation_loader = torch.utils.data.DataLoader(validation_dset,
                                                batch_size=10,
                                                num_workers=4,
                                                shuffle=True)
'''
def create_compressed_data(data_mode, data_T, device, pt_filename):
    autoencoder.load_state_dict(torch.load(pt_filename))
    data_T = torch.from_numpy(data_T)
    encoded_data, decoded_data = autoencoder(data_T.to(device).float())
    data_T = data_T.numpy()
    data_compressed = encoded_data.detach().cpu().numpy()



    return data_compressed

'''

def epoch_time(start_time, end_time):
    elapsed_time = end_time - start_time
    elapsed_mins = int(elapsed_time / 60)
    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))
    return elapsed_mins, elapsed_secs

'''-------------------------------------------------------------------------'''
'''--------------------------- Hyper Parameters ----------------------------'''
'''-------------------------------------------------------------------------'''
EPOCH = 100
BATCH_SIZE = 128
LR = 0.0001  # learning rate
CLIP = 2
# baseline 100th measurement in Rawdata_data00025

N_FILE = 2

BASELINE_FILE = 197
BASELINE_MEASUREMENT = 1

Loading_DATA = True
SAVE_CREATED_DATA = True
WITH_MASS_LABEL = True

ANALYSIS_DATA = True
TRAIN = True
EVALUATE = False
COMPRRSSION_DATA = True


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

autoencoder = IntroVAE().to(device)
# optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR)

loss_record = []
correlationCoefficientList = []
correlationCoefficientList_eva = []

if TRAIN:


  for epoch in range(EPOCH):

      start_time = time.time()
      loss1 = 0
      loss2 = 0
      batch_num = 0

      for i, (x, label) in enumerate(train_loader):
         x = x.to(device)
         encoder_loss, decoder_loss, xr = autoencoder(x)
         loss1 += float(encoder_loss)
         loss2 += float(decoder_loss)
         batch_num = batch_num + 1

         if i % 40 == 0:
            print("encoder_lossxxx:", loss1)
            print("decoder_lossxxx:", loss2)

         if i % 100 == 0:
            img_true = x[0].cpu().numpy()
            img_true = np.transpose(img_true, (1, 2, 0))  # 把channel那一维放到最后
            plt.imshow(img_true)
            plt.show()

            img_decoded = xr[0].cpu().detach().numpy()
            img_decoded = np.transpose(img_decoded, (1, 2, 0))  # 把channel那一维放到最后
            plt.imshow(img_decoded)
            plt.show()

      end_time = time.time()
      epoch_mins, epoch_secs = epoch_time(start_time, end_time)
      print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')
      print(f'\tencoder_loss: {loss1/batch_num:.3f}')
      print(f'\tdecoder_loss: {loss2/batch_num:.3f}')
